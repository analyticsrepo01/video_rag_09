{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6183aeb-70d1-4dd2-aebe-82a5b8758cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c01949-08fe-4e38-82e5-b3172692f1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "# Define constants\n",
    "PROJECT_ID = \"my-project-0004-346516\"\n",
    "LOCATION = \"us-central1\"\n",
    "API_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
    "SHOTS_FILE_PATH = \"../shots.csv\"\n",
    "CLIPS_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604b6bc4-4785-42a4-87ca-3dd868b056a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def list_deployed_indexes():\n",
    "    \"\"\"List all deployed indexes in Vertex AI Matching Engine.\"\"\"\n",
    "    client = aiplatform.gapic.IndexEndpointServiceClient(\n",
    "        client_options={\"api_endpoint\": API_ENDPOINT}\n",
    "    )\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n",
    "    index_list = []\n",
    "\n",
    "    # List all index endpoints\n",
    "    for index_endpoint in client.list_index_endpoints(parent=parent):\n",
    "        for deployed_index in index_endpoint.deployed_indexes:\n",
    "            index_list.append({\n",
    "                \"index_endpoint_name\": index_endpoint.name,\n",
    "                \"deployed_index_id\": deployed_index.id,\n",
    "                \"display_name\": index_endpoint.display_name\n",
    "            })\n",
    "\n",
    "    return index_list\n",
    "\n",
    "def get_embeddings(query, model):\n",
    "    \"\"\"Generate embeddings for the query using the specified model.\"\"\"\n",
    "    embeddings = model.get_embeddings([query])\n",
    "    return embeddings[0].values\n",
    "\n",
    "def load_shots_df(file_path):\n",
    "    \"\"\"Load shots_df from a local CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b74255-6889-40dd-800a-1620027dc0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shots DataFrame loaded successfully.\n",
      "Deployed indexes found:\n",
      "  - darryl-testing-lh-pytorch112kagglewbi (darryl_testing_lh_pytorch112kagglewbi)\n",
      "Selected index: darryl-testing-lh-pytorch112kagglewbi with ID darryl_testing_lh_pytorch112kagglewbi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ... [Your existing functions: list_deployed_indexes, get_embeddings, load_shots_df remain the same] ...\n",
    "\n",
    "# --- Start of Jupyter Notebook Conversion ---\n",
    "\n",
    "# 1. Initialization and Data Loading\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@latest\")\n",
    "\n",
    "# Load shots data\n",
    "shots_df = load_shots_df(SHOTS_FILE_PATH)\n",
    "print(\"Shots DataFrame loaded successfully.\")  # Add a print statement for confirmation\n",
    "\n",
    "# 2. List Deployed Indexes\n",
    "\n",
    "deployed_indexes = list_deployed_indexes()\n",
    "\n",
    "if deployed_indexes:\n",
    "    print(\"Deployed indexes found:\")\n",
    "    for index in deployed_indexes:\n",
    "        print(f\"  - {index['display_name']} ({index['deployed_index_id']})\")\n",
    "else:\n",
    "    print(\"No deployed indexes found. Please check your Vertex AI Matching Engine setup.\")\n",
    "\n",
    "# --- Manual Index Selection (Replace with user input in Streamlit later) ---\n",
    "selected_index = deployed_indexes[0]  # Select the first index for now (or prompt the user for input)\n",
    "print(f\"Selected index: {selected_index['display_name']} with ID {selected_index['deployed_index_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61c2a42e-f348-49ab-8c5b-eb6d14da0abe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain_google_vertexai in /opt/conda/lib/python3.10/site-packages (1.0.10)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.56.0 in /opt/conda/lib/python3.10/site-packages (from langchain_google_vertexai) (1.65.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.17.0 in /opt/conda/lib/python3.10/site-packages (from langchain_google_vertexai) (2.17.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from langchain_google_vertexai) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain_google_vertexai) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in /opt/conda/lib/python3.10/site-packages (from langchain_google_vertexai) (0.2.39)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.19.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (3.19.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.0.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.7.4)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (1.5.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (3.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (0.1.117)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.62.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.26.4)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip show langchain_core\n",
    "# !pip install --upgrade langchain_core\n",
    "%pip install --upgrade langchain_google_vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed112023-700f-4229-9f71-193763831500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextEmbeddingModel' object has no attribute 'embed_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me the clips where there are animals present\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m TextEmbeddingModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextembedding-gecko@003\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m test_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m(query)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextEmbeddingModel' object has no attribute 'embed_query'"
     ]
    }
   ],
   "source": [
    "# from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "query = \"Give me the clips where there are animals present\"\n",
    "\n",
    "embeddings = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")\n",
    "\n",
    "\n",
    "test_embeddings = embeddings.get_embeddings(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9bcde1a-861d-4f5a-94a4-2783c3d6e3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VertexAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me the clips where there are animals present\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mVertexAIEmbeddings\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextembedding-gecko@003\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextembedding-gecko@003\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Configure Vector Search client\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VertexAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Configure Vector Search client\n",
    "client_options = {\n",
    "  \"api_endpoint\": API_ENDPOINT\n",
    "}\n",
    "vector_search_client = aiplatform_v1.MatchServiceClient(\n",
    "  client_options=client_options,\n",
    ")\n",
    "# Build FindNeighborsRequest object\n",
    "datapoint = aiplatform_v1.IndexDatapoint(\n",
    "  feature_vector=test_embeddings\n",
    ")\n",
    "\n",
    "query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "  datapoint=datapoint,\n",
    "  # The number of nearest neighbors to be retrieved\n",
    "  neighbor_count=neighbor_count\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "request = aiplatform_v1.FindNeighborsRequest(\n",
    "  index_endpoint=INDEX_ENDPOINT,\n",
    "  deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "  # Request can have multiple queries\n",
    "  queries=[query],\n",
    "  return_full_datapoint=False,\n",
    ")\n",
    "\n",
    "# Execute the request\n",
    "response = vector_search_client.find_neighbors(request)\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "print('neighbor_count', neighbor_count)\n",
    "\n",
    "shots_df['distance'] = None\n",
    "\n",
    "for i in range(0,neighbor_count):\n",
    "    x=response.nearest_neighbors[0]\n",
    "    \n",
    "    df_match = shots_df.loc[shots_df['id'] == int(x.neighbors[i].datapoint.datapoint_id) ]\n",
    "    df_match['distance'] = x.neighbors[i].distance\n",
    "\n",
    "    # Append the matching rows to the new DataFrame\n",
    "    df_new = pd.concat([df_new, df_match])\n",
    "    \n",
    "\n",
    "# Print the new DataFrame\n",
    "df_sorted = df_new.sort_values(by=\"distance\", ascending=True)\n",
    "print(display(df_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8953a731-f8ee-4637-8ff5-740fe6240d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding generated.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'google.cloud.aiplatform' has no attribute 'MatchServiceClient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     17\u001b[0m find_neighbors_request \u001b[38;5;241m=\u001b[39m aiplatform_v1\u001b[38;5;241m.\u001b[39mFindNeighborsRequest(\n\u001b[1;32m     18\u001b[0m     index_endpoint\u001b[38;5;241m=\u001b[39mindex_endpoint_name,\n\u001b[1;32m     19\u001b[0m     deployed_index_id\u001b[38;5;241m=\u001b[39mdeployed_index_id,\n\u001b[1;32m     20\u001b[0m     queries\u001b[38;5;241m=\u001b[39m[find_neighbors_query],\n\u001b[1;32m     21\u001b[0m     return_full_datapoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Initialize MatchServiceClient\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m match_service_client \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMatchServiceClient\u001b[49m(client_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: API_ENDPOINT})\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Execute the request\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.cloud.aiplatform' has no attribute 'MatchServiceClient'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Query and Retrieval\n",
    "\n",
    "# --- Get user query (Replace with Streamlit input later) ---\n",
    "query = \"where is apples discussed\"  # Get query from user input in Streamlit\n",
    "\n",
    "# Generate query embedding\n",
    "query_embedding = get_embeddings(query, text_embedding_model)\n",
    "print(\"Query embedding generated.\")\n",
    "\n",
    "# Extract index details\n",
    "deployed_index_id = selected_index['deployed_index_id']\n",
    "index_endpoint_name = selected_index['index_endpoint_name']\n",
    "\n",
    "# Build FindNeighborsRequest\n",
    "datapoint = aiplatform_v1.IndexDatapoint(feature_vector=query_embedding)\n",
    "find_neighbors_query = aiplatform_v1.FindNeighborsRequest.Query(datapoint=datapoint, neighbor_count=3)\n",
    "find_neighbors_request = aiplatform_v1.FindNeighborsRequest(\n",
    "    index_endpoint=index_endpoint_name,\n",
    "    deployed_index_id=deployed_index_id,\n",
    "    queries=[find_neighbors_query],\n",
    "    return_full_datapoint=False\n",
    ")\n",
    "\n",
    "# Initialize MatchServiceClient\n",
    "match_service_client = aiplatform_v1.MatchServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "\n",
    "# Execute the request\n",
    "try:\n",
    "    response = match_service_client.find_neighbors(find_neighbors_request)\n",
    "    print(\"Find Neighbors request executed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during query execution: {e}\")\n",
    "    print(f\"API Endpoint: {API_ENDPOINT}\")\n",
    "    print(f\"Index Endpoint: {index_endpoint_name}\")\n",
    "    print(f\"Deployed Index ID: {deployed_index_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1febbe3e-c4ec-4751-9b64-7f4e1441f602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Query: {query}, Type: {type(query)}\") \n",
    "find_neighbors_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "533bdd56-8b2f-44bc-85ed-5a46c19bfe76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[MatchNeighbor(id='8', distance=0.5725300908088684, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='9', distance=0.5668851137161255, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='7', distance=0.5605428814888, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='4', distance=0.5574842691421509, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]\n"
     ]
    }
   ],
   "source": [
    "# response = match_service_client.find_neighbors(find_neighbors_request)\n",
    "# print(response)\n",
    "# print(find_neighbors_query)\n",
    "\n",
    "# Create the index endpoint instance from an existing endpoint.\n",
    "my_index_endpoint_main = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name=index_endpoint_name\n",
    ")\n",
    "\n",
    "# Query the index endpoint for the nearest neighbors.\n",
    "response = my_index_endpoint_main.find_neighbors(\n",
    "    deployed_index_id=deployed_index_id,\n",
    "    queries=[query_embedding],\n",
    "    num_neighbors=4,\n",
    "    return_full_datapoint=False,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d3a5c5-1ecc-4c07-b979-44169f5ce661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'nearest_neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Process and Display Results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Prepare results DataFrame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnearest_neighbors\u001b[49m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mneighbors:\n\u001b[1;32m      7\u001b[0m         clip_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(neighbor\u001b[38;5;241m.\u001b[39mdatapoint\u001b[38;5;241m.\u001b[39mdatapoint_id)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'nearest_neighbors'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Process and Display Results\n",
    "\n",
    "# Prepare results DataFrame\n",
    "results = []\n",
    "for result in response.nearest_neighbors:\n",
    "    for neighbor in result.neighbors:\n",
    "        clip_id = int(neighbor.datapoint.datapoint_id)\n",
    "        distance = neighbor.distance\n",
    "        df_match = shots_df.loc[shots_df.index == clip_id]\n",
    "        if not df_match.empty:\n",
    "            match_info = df_match.iloc[0].to_dict()\n",
    "            match_info['distance'] = distance\n",
    "            results.append(match_info)\n",
    "\n",
    "df_new = pd.DataFrame(results)\n",
    "\n",
    "# Sort and display results\n",
    "df_sorted = df_new.sort_values(by=\"distance\", ascending=True)\n",
    "print(\"Matching clips:\")\n",
    "print(df_sorted[[\"clip_name\", \"description\", \"distance\"]])\n",
    "\n",
    "# --- Display videos (Adapt for Jupyter Notebook) ---\n",
    "# You might need to use a library like IPython.display to display videos in a notebook\n",
    "# for index, row in df_sorted.iterrows():\n",
    "#     print(f\"Clip Name: {row['clip_name']}\")\n",
    "#     video_path = CLIPS_DIR + row['clip_name']\n",
    "#     # Display video using IPython.display or another suitable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fb75b-4601-436b-92a4-e94a785b6ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
